{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Load the data as a pandas dataframe\n",
    "df = pd.read_csv(\"dataexercise2.csv\")\n",
    "\n",
    "# Convert the dataframe to a numpy array (for easier manipulation)\n",
    "arr = df.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# Define functions to calculate foundamental values\n",
    "def calc_gradient(x, y, thetas):\n",
    "    # Calculate the gradient of the log likelihood\n",
    "\treturn -x.T @ np.exp(x @ thetas.T) + x.T @ y\n",
    "\n",
    "def calc_hessian_inverse(x, thetas):\n",
    "    # Calculate the hessian matrix of the log likelihood\n",
    "    hess = -x.T @ np.diag(np.exp(x @ thetas.T)) @ x\n",
    "    return np.linalg.inv(hess)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "# first 4 columns are features (x matrix)\n",
    "# last column is label (y vector)\n",
    "x = arr[:, :-1]\n",
    "y = arr[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# Sample thetas from prior distribution\n",
    "featNum = x.shape[1]\n",
    "std0 = 4\n",
    "thetas = np.random.multivariate_normal(np.zeros(featNum), std0**2*np.eye(featNum))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 36 iterations\n",
      "[ 1.12777336  0.42858431  0.01512131 -0.05416601]\n",
      "[[ 0.03140956 -0.00820031  0.00116572 -0.00139328]\n",
      " [-0.00820031  0.00305825 -0.00031134  0.00066138]\n",
      " [ 0.00116572 -0.00031134  0.0148073  -0.0014676 ]\n",
      " [-0.00139328  0.00066138 -0.0014676   0.01173136]]\n"
     ]
    }
   ],
   "source": [
    "# Newton algorithm implementation\n",
    "iters = 1000\n",
    "e = 1e-6\n",
    "\n",
    "for i in range(iters):\n",
    "    grad = calc_gradient(x, y, thetas)\n",
    "    hess_inv = calc_hessian_inverse(x, thetas)\n",
    "    update = grad @ hess_inv\n",
    "    if np.any(np.abs(update)) > e:\n",
    "        thetas = thetas - update\n",
    "    else:\n",
    "        print(\"Converged after {} iterations\".format(i + 1))\n",
    "        break\n",
    "\n",
    "# Calculate the gaussian distribution of thetas with Laplace approximation\n",
    "mean = thetas\n",
    "cov = -calc_hessian_inverse(x, thetas)\n",
    "print(mean)\n",
    "print(cov)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-95701864",
   "language": "python",
   "display_name": "PyCharm (MachineLearning1_exercises)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}